{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/dchipping/project/dan-track/mot-gym/mot_gym/data/MOT17/train/MOT17-05\n",
      "Starting tracker in RL train mode, this will freeze the gallery\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "\n",
    "os.unsetenv(\"SESSION_MANAGER\") # Supress rendering issue\n",
    "\n",
    "env = gym.make(\"mot_gym:BasicMOT-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs, info = env.reset()\n",
    "obs = env.reset()\n",
    "# print(f\"Frame: {info['curr_frame']}, TrackIDs: {info['tracks_ids']}\")\n",
    "# env.render()\n",
    "\n",
    "done = False\n",
    "while not done: \n",
    "    obs, reward, done, info = env.step(1)#env.action_space.sample())\n",
    "    if info['curr_frame'] % 10 == 0 and info['curr_track']['track_idx'] == 0:\n",
    "        print(f\"Frame: {info['curr_frame']}, TrackIDs: {info['tracks_ids']}\")\n",
    "    # env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL Lib\n",
    "import ray\n",
    "import sys\n",
    "# sys.setrecursionlimit(3000)\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.init()\n",
    "from ray import rllib\n",
    "rllib.utils.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=75027)\u001b[0m Loading data from: /home/dchipping/project/dan-track/mot-gym/mot_gym/data/MOT17/train/MOT17-05\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=75027)\u001b[0m Starting tracker in RL train mode, this will freeze the gallery\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=75033)\u001b[0m Loading data from: /home/dchipping/project/dan-track/mot-gym/mot_gym/data/MOT17/train/MOT17-05\n"
     ]
    }
   ],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"framework\"] = \"torch\"\n",
    "config[\"num_gpus\"] = 1\n",
    "config[\"num_workers\"] = 7\n",
    "\n",
    "# trainer = ppo.PPOTrainer(config=config, env=\"test_basic:test-v2\")\n",
    "trainer = ppo.PPOTrainer(config=config, env=\"mot_gym:BasicMOT-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dchipping/project/dan-track/demo2.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39m# Train using env\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=2'>3</a>\u001b[0m    \u001b[39m# Perform one iteration of training the policy with PPO\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=3'>4</a>\u001b[0m    result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=4'>5</a>\u001b[0m    \u001b[39mprint\u001b[39m(pretty_print(result))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dchipping/project/dan-track/demo2.ipynb#ch0000005?line=6'>7</a>\u001b[0m    \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/tune/trainable.py:360\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warmup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n\u001b[1;32m    359\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 360\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    361\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mstep() needs to return a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[39m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m step_ctx\u001b[39m.\u001b[39mshould_stop(step_attempt_results):\n\u001b[1;32m   1110\u001b[0m     \u001b[39m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m         step_attempt_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_attempt()\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# @ray.remote RolloutWorker failure.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39mexcept\u001b[39;00m RayError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1115\u001b[0m         \u001b[39m# Try to recover w/o the failed worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer.step_attempt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m-> 1214\u001b[0m     step_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_plan_or_training_iteration_fn()\n\u001b[1;32m   1215\u001b[0m \u001b[39m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m     \u001b[39m# No parallelism.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mevaluation_parallel_to_training\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:2209\u001b[0m, in \u001b[0;36mTrainer._exec_plan_or_training_iteration_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timers[TRAINING_ITERATION_TIMER]:\n\u001b[1;32m   2208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39m_disable_execution_plan_api\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m-> 2209\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_iteration()\n\u001b[1;32m   2210\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2211\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_exec_impl)\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/rllib/agents/ppo/ppo.py:437\u001b[0m, in \u001b[0;36mPPOTrainer.training_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    434\u001b[0m         worker_set\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers, max_agent_steps\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain_batch_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    436\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m     train_batch \u001b[39m=\u001b[39m synchronous_parallel_sample(\n\u001b[1;32m    438\u001b[0m         worker_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkers, max_env_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mtrain_batch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    440\u001b[0m train_batch \u001b[39m=\u001b[39m train_batch\u001b[39m.\u001b[39mas_multi_agent()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_counters[NUM_AGENT_STEPS_SAMPLED] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_batch\u001b[39m.\u001b[39magent_steps()\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/rllib/execution/rollout_ops.py:99\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[0;34m(worker_set, max_agent_steps, max_env_steps, concat)\u001b[0m\n\u001b[1;32m     96\u001b[0m     sample_batches \u001b[39m=\u001b[39m [worker_set\u001b[39m.\u001b[39mlocal_worker()\u001b[39m.\u001b[39msample()]\n\u001b[1;32m     97\u001b[0m \u001b[39m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     sample_batches \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    100\u001b[0m         [worker\u001b[39m.\u001b[39;49msample\u001b[39m.\u001b[39;49mremote() \u001b[39mfor\u001b[39;49;00m worker \u001b[39min\u001b[39;49;00m worker_set\u001b[39m.\u001b[39;49mremote_workers()]\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[39m# Update our counters for the stopping criterion of the while loop.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m sample_batches:\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/worker.py:1825\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an object ref \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a list of object refs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m     )\n\u001b[1;32m   1824\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 1825\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1826\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   1827\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/miniconda3/envs/FairMOT/lib/python3.8/site-packages/ray/worker.py:364\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    359\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    363\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 364\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    365\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    366\u001b[0m )\n\u001b[1;32m    367\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m \u001b[39mfor\u001b[39;00m (data, metadata) \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1200\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:169\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train using env\n",
    "for i in range(1):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = trainer.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 10 == 0:\n",
    "       checkpoint = trainer.save()\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('FairMOT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7ce69a9c48907c8d83ae3629e84d6226851d3be7e4bf2483773f5d03f113ef1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
